{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844fac8e-a86c-47f8-b915-2e9ca68b00c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_180259/4189609880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReddit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    214\u001b[0m         r\"\"\"Performs tensor device conversion, either for all attributes or\n\u001b[1;32m    215\u001b[0m         only the ones given in :obj:`*args`.\"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         return self.apply(\n\u001b[0m\u001b[1;32m    217\u001b[0m             lambda x: x.to(device=device, non_blocking=non_blocking), *args)\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    197\u001b[0m         the ones given in :obj:`*args`.\"\"\"\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    146\u001b[0m         the ones given in :obj:`*args`.\"\"\"\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecursive_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPackedSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    215\u001b[0m         only the ones given in :obj:`*args`.\"\"\"\n\u001b[1;32m    216\u001b[0m         return self.apply(\n\u001b[0;32m--> 217\u001b[0;31m             lambda x: x.to(device=device, non_blocking=non_blocking), *args)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.datasets import Reddit\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "# download and loading the obg dataset\n",
    "path = osp.join(osp.dirname(osp.realpath('./')), 'data', 'Reddit')\n",
    "dataset = Reddit(path)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device, 'x', 'y')\n",
    "\n",
    "BS=2048\n",
    "kwargs = {'batch_size': BS, 'num_workers': 6, 'persistent_workers': True}\n",
    "train_loader = NeighborLoader(data, input_nodes=data.train_mask,\n",
    "                              num_neighbors=[25, 10], shuffle=True, **kwargs)\n",
    "\n",
    "subgraph_loader = NeighborLoader(copy.copy(data), input_nodes=None,\n",
    "                                 num_neighbors=[-1], shuffle=False, **kwargs)\n",
    "# No need to maintain these features during evaluation:\n",
    "del subgraph_loader.data.x, subgraph_loader.data.y\n",
    "# Add global node index information.\n",
    "subgraph_loader.data.num_nodes = data.num_nodes\n",
    "subgraph_loader.data.n_id = torch.arange(data.num_nodes)\n",
    "# Already send node features/labels to GPU for faster access during sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b281a39-3e5c-4324-ad94-45b244f493f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  549652 KB |  549652 KB |  549652 KB |       0 B  |\n",
      "|       from large pool |  549652 KB |  549652 KB |  549652 KB |       0 B  |\n",
      "|       from small pool |       0 KB |       0 KB |       0 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  549652 KB |  549652 KB |  549652 KB |       0 B  |\n",
      "|       from large pool |  549652 KB |  549652 KB |  549652 KB |       0 B  |\n",
      "|       from small pool |       0 KB |       0 KB |       0 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  569344 KB |  569344 KB |  569344 KB |       0 B  |\n",
      "|       from large pool |  569344 KB |  569344 KB |  569344 KB |       0 B  |\n",
      "|       from small pool |       0 KB |       0 KB |       0 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   19691 KB |   19691 KB |   19691 KB |       0 B  |\n",
      "|       from large pool |   19691 KB |   19691 KB |   19691 KB |       0 B  |\n",
      "|       from small pool |       0 KB |       0 KB |       0 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       2    |       2    |       2    |       0    |\n",
      "|       from large pool |       2    |       2    |       2    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       2    |       2    |       2    |       0    |\n",
      "|       from large pool |       2    |       2    |       2    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       2    |       2    |       2    |       0    |\n",
      "|       from large pool |       2    |       2    |       2    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       2    |       2    |       2    |       0    |\n",
      "|       from large pool |       2    |       2    |       2    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6846bee7-8810-455e-9354-f8f1fef620c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.001\n",
    "HC=8\n",
    "NC=3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device, 'x', 'y')\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for i in range(NC-2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < len(self.convs) - 1:\n",
    "                x = x.relu_()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "            if i < len(self.convs) - 1 and i>0:\n",
    "                x = conv(x, edge_index)\n",
    "                x = x.relu_()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def inference(self, x_all, subgraph_loader):\n",
    "        print(\"testtest\")\n",
    "        pbar = tqdm(total=len(subgraph_loader.dataset) * len(self.convs))\n",
    "        pbar.set_description('Evaluating')\n",
    "\n",
    "        # Compute representations of nodes layer by layer, using *all*\n",
    "        # available edges. This leads to faster computation in contrast to\n",
    "        # immediately computing the final representations of each batch:\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            xs = []\n",
    "            for batch in subgraph_loader:\n",
    "                x = x_all[batch.n_id.to(x_all.device)].to(device)\n",
    "                x = conv(x, batch.edge_index.to(device))\n",
    "                if i < len(self.convs) - 1:\n",
    "                    x = x.relu_()\n",
    "                xs.append(x[:batch.batch_size].cpu())\n",
    "                pbar.update(batch.batch_size)\n",
    "            x_all = torch.cat(xs, dim=0)\n",
    "            if i < len(self.convs) - 1 and i>0:\n",
    "                xs = []\n",
    "                for batch in subgraph_loader:\n",
    "                    x = x_all[batch.n_id.to(x_all.device)].to(device)\n",
    "                    x = conv(x, batch.edge_index.to(device))\n",
    "                    x = x.relu_()\n",
    "                    xs.append(x[:batch.batch_size].cpu())\n",
    "                x_all = torch.cat(xs, dim=0)\n",
    "        pbar.close()\n",
    "        return x_all\n",
    "    \n",
    "model = SAGE(dataset.num_features, HC, dataset.num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(total=int(len(train_loader.dataset)))\n",
    "    pbar.set_description(f'Epoch {epoch:02d}')\n",
    "\n",
    "    total_loss = total_correct = total_examples = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y = batch.y[:batch.batch_size]\n",
    "        y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * batch.batch_size\n",
    "        total_correct += int((y_hat.argmax(dim=-1) == y).sum())\n",
    "        total_examples += batch.batch_size\n",
    "        pbar.update(batch.batch_size)\n",
    "    \n",
    "    pbar.close()\n",
    "\n",
    "    return total_loss / total_examples, total_correct / total_examples\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    y_hat = model.inference(data.x, subgraph_loader).argmax(dim=-1)\n",
    "    y = data.y.to(y_hat.device)\n",
    "\n",
    "    accs = []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        accs.append(int((y_hat[mask] == y[mask]).sum()) / int(mask.sum()))\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9630c78a-2127-4134-a1d0-41d3ed5412c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 3         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    1073 MB |    4387 MB |    4456 GB |    4455 GB |\n",
      "|       from large pool |    1073 MB |    4386 MB |    4446 GB |    4445 GB |\n",
      "|       from small pool |       0 MB |       2 MB |       9 GB |       9 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    1073 MB |    4387 MB |    4456 GB |    4455 GB |\n",
      "|       from large pool |    1073 MB |    4386 MB |    4446 GB |    4445 GB |\n",
      "|       from small pool |       0 MB |       2 MB |       9 GB |       9 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    4914 MB |    5648 MB |   14382 MB |    9468 MB |\n",
      "|       from large pool |    4912 MB |    5644 MB |   14374 MB |    9462 MB |\n",
      "|       from small pool |       2 MB |       4 MB |       8 MB |       6 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  473428 KB |    3438 MB |    2183 GB |    2182 GB |\n",
      "|       from large pool |  471511 KB |    3436 MB |    2169 GB |    2169 GB |\n",
      "|       from small pool |    1917 KB |       2 MB |      13 GB |      13 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      31    |      68    |  252210    |  252179    |\n",
      "|       from large pool |       4    |      23    |  122937    |  122933    |\n",
      "|       from small pool |      27    |      45    |  129273    |  129246    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      31    |      68    |  252210    |  252179    |\n",
      "|       from large pool |       4    |      23    |  122937    |  122933    |\n",
      "|       from small pool |      27    |      45    |  129273    |  129246    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       7    |      11    |      21    |      14    |\n",
      "|       from large pool |       6    |       9    |      17    |      11    |\n",
      "|       from small pool |       1    |       2    |       4    |       3    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       9    |      14    |   95112    |   95103    |\n",
      "|       from large pool |       4    |      10    |   49849    |   49845    |\n",
      "|       from small pool |       5    |       5    |   45263    |   45258    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5c16048-5579-4fc0-a0dd-b7add61f685d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: 100%|██████████| 153431/153431 [00:04<00:00, 36769.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Loss: 3.5768, Approx. Train: 0.0613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|██████████| 153431/153431 [00:04<00:00, 37602.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02, Loss: 2.9223, Approx. Train: 0.1979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|██████████| 153431/153431 [00:04<00:00, 37794.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03, Loss: 2.3836, Approx. Train: 0.3421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|██████████| 153431/153431 [00:03<00:00, 40039.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04, Loss: 2.0031, Approx. Train: 0.4481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05: 100%|██████████| 153431/153431 [00:04<00:00, 36631.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05, Loss: 1.7077, Approx. Train: 0.5334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06: 100%|██████████| 153431/153431 [00:04<00:00, 38254.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06, Loss: 1.4882, Approx. Train: 0.6014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07: 100%|██████████| 153431/153431 [00:03<00:00, 38789.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07, Loss: 1.3454, Approx. Train: 0.6418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08: 100%|██████████| 153431/153431 [00:03<00:00, 39435.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08, Loss: 1.2443, Approx. Train: 0.6744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09: 100%|██████████| 153431/153431 [00:04<00:00, 37223.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09, Loss: 1.1734, Approx. Train: 0.6974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 153431/153431 [00:04<00:00, 38184.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.1266, Approx. Train: 0.7159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 153431/153431 [00:04<00:00, 34915.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.0827, Approx. Train: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 153431/153431 [00:03<00:00, 38640.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 1.0477, Approx. Train: 0.7422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 153431/153431 [00:04<00:00, 37864.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 1.0185, Approx. Train: 0.7530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 153431/153431 [00:03<00:00, 38730.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.9929, Approx. Train: 0.7611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 153431/153431 [00:03<00:00, 39139.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.9696, Approx. Train: 0.7706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 153431/153431 [00:04<00:00, 38351.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.9503, Approx. Train: 0.7769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 153431/153431 [00:04<00:00, 37383.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.9364, Approx. Train: 0.7810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 153431/153431 [00:03<00:00, 39491.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.9195, Approx. Train: 0.7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 153431/153431 [00:03<00:00, 38626.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.9068, Approx. Train: 0.7889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 153431/153431 [00:04<00:00, 35455.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.9022, Approx. Train: 0.7908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 153431/153431 [00:04<00:00, 38172.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 0.8903, Approx. Train: 0.7943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 153431/153431 [00:04<00:00, 38163.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 0.8791, Approx. Train: 0.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 153431/153431 [00:03<00:00, 38550.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 0.8734, Approx. Train: 0.7992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 153431/153431 [00:04<00:00, 38282.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 0.8675, Approx. Train: 0.8007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 153431/153431 [00:03<00:00, 40210.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 0.8569, Approx. Train: 0.8036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 153431/153431 [00:04<00:00, 37539.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 0.8543, Approx. Train: 0.8042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 153431/153431 [00:04<00:00, 37404.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 0.8483, Approx. Train: 0.8062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 153431/153431 [00:03<00:00, 40461.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 0.8389, Approx. Train: 0.8088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 153431/153431 [00:03<00:00, 38742.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 0.8382, Approx. Train: 0.8093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 153431/153431 [00:04<00:00, 38010.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 0.8304, Approx. Train: 0.8115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 153431/153431 [00:03<00:00, 39433.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 0.8296, Approx. Train: 0.8118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 153431/153431 [00:03<00:00, 39500.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Loss: 0.8197, Approx. Train: 0.8135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 153431/153431 [00:03<00:00, 38933.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Loss: 0.8190, Approx. Train: 0.8139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 153431/153431 [00:04<00:00, 36153.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Loss: 0.8141, Approx. Train: 0.8154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 153431/153431 [00:04<00:00, 37332.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Loss: 0.8120, Approx. Train: 0.8168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 153431/153431 [00:03<00:00, 38392.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Loss: 0.8066, Approx. Train: 0.8170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 153431/153431 [00:04<00:00, 38149.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Loss: 0.8066, Approx. Train: 0.8178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 153431/153431 [00:04<00:00, 38320.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Loss: 0.8013, Approx. Train: 0.8190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 153431/153431 [00:04<00:00, 37519.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Loss: 0.7986, Approx. Train: 0.8193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 153431/153431 [00:03<00:00, 40047.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 0.7983, Approx. Train: 0.8204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 153431/153431 [00:04<00:00, 37022.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Loss: 0.7912, Approx. Train: 0.8213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 153431/153431 [00:03<00:00, 39020.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Loss: 0.7913, Approx. Train: 0.8213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 153431/153431 [00:04<00:00, 38119.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Loss: 0.7875, Approx. Train: 0.8226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 153431/153431 [00:04<00:00, 36382.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Loss: 0.7837, Approx. Train: 0.8224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 153431/153431 [00:04<00:00, 38205.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Loss: 0.7814, Approx. Train: 0.8242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 153431/153431 [00:03<00:00, 41105.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Loss: 0.7839, Approx. Train: 0.8238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 153431/153431 [00:03<00:00, 39231.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Loss: 0.7807, Approx. Train: 0.8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 153431/153431 [00:04<00:00, 35896.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Loss: 0.7835, Approx. Train: 0.8258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 153431/153431 [00:03<00:00, 38424.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Loss: 0.7726, Approx. Train: 0.8258\n",
      "testtest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 698895/698895 [00:29<00:00, 23380.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Train: 0.8395, Val: 0.8536, Test: 0.8526\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 50):\n",
    "    loss, acc = train(epoch)\n",
    "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}')\n",
    "train_acc, val_acc, test_acc = test()\n",
    "print(f'Epoch: {epoch:02d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
    "      f'Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19ec0ef7-d08b-48b3-925e-33b366b12770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 3         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    1073 MB |    4387 MB |   11728 GB |   11727 GB |\n",
      "|       from large pool |    1073 MB |    4386 MB |   11703 GB |   11702 GB |\n",
      "|       from small pool |       0 MB |       2 MB |      25 GB |      25 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    1073 MB |    4387 MB |   11728 GB |   11727 GB |\n",
      "|       from large pool |    1073 MB |    4386 MB |   11703 GB |   11702 GB |\n",
      "|       from small pool |       0 MB |       2 MB |      25 GB |      25 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    4916 MB |    5648 MB |   14384 MB |    9468 MB |\n",
      "|       from large pool |    4912 MB |    5644 MB |   14374 MB |    9462 MB |\n",
      "|       from small pool |       4 MB |       4 MB |      10 MB |       6 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  473298 KB |    3438 MB |   11193 GB |   11192 GB |\n",
      "|       from large pool |  471511 KB |    3436 MB |   11156 GB |   11155 GB |\n",
      "|       from small pool |    1787 KB |       2 MB |      36 GB |      36 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      58    |      86    |  675396    |  675338    |\n",
      "|       from large pool |       4    |      23    |  328368    |  328364    |\n",
      "|       from small pool |      54    |      63    |  347028    |  346974    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      58    |      86    |  675396    |  675338    |\n",
      "|       from large pool |       4    |      23    |  328368    |  328364    |\n",
      "|       from small pool |      54    |      63    |  347028    |  346974    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       8    |      11    |      22    |      14    |\n",
      "|       from large pool |       6    |       9    |      17    |      11    |\n",
      "|       from small pool |       2    |       2    |       5    |       3    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       6    |      15    |  257609    |  257603    |\n",
      "|       from large pool |       4    |      12    |  135834    |  135830    |\n",
      "|       from small pool |       2    |       6    |  121775    |  121773    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "SAGEConv(602, 8)\n",
      "SAGEConv(8, 8)\n",
      "SAGEConv(8, 41)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())\n",
    "for i, conv in enumerate(model.convs):\n",
    "    print(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eebe59e-e5ff-4c51-948b-0c0785bae407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58217e8b-7280-4978-8f44-404ac7124840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e28460-c4f7-49aa-bcdc-4107a9b2bdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
