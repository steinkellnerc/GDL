{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f533900-ef7e-45b4-b786-060f27e9410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path as osp\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from time import *\n",
    "\n",
    "from torch_geometric.datasets import Reddit\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "# download and loading the obg dataset\n",
    "path = osp.join(osp.dirname(osp.realpath('./')), 'data', 'Reddit')\n",
    "dataset = Reddit(path)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device, 'x', 'y')\n",
    "\n",
    "BS=4096\n",
    "kwargs = {'batch_size': BS, 'num_workers': 6, 'persistent_workers': True}\n",
    "train_loader = NeighborLoader(data, input_nodes=data.train_mask,\n",
    "                              num_neighbors=[25, 10], shuffle=True, **kwargs)\n",
    "test_loader = NeighborLoader(data, input_nodes=data.test_mask,\n",
    "                              num_neighbors=[25, 10], shuffle=True, **kwargs)\n",
    "val_loader = NeighborLoader(data, input_nodes=data.val_mask,\n",
    "                              num_neighbors=[25, 10], shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf5770f-fc85-41bc-97f5-3ab92358e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for i in range(NC-2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < len(self.convs) - 1:\n",
    "                x = x.relu_()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "            if i < len(self.convs) - 1 and i>0:\n",
    "                x = conv(x, edge_index)\n",
    "                x = x.relu_()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x\n",
    "    \n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    #pbar = tqdm(total=int(len(train_loader.dataset)))\n",
    "    #pbar.set_description(f'Epoch {epoch:02d}')\n",
    "\n",
    "    total_loss = total_correct = total_examples = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y = batch.y[:batch.batch_size]\n",
    "        y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * batch.batch_size\n",
    "        total_correct += int((y_hat.argmax(dim=-1) == y).sum())\n",
    "        total_examples += batch.batch_size\n",
    "        #pbar.update(batch.batch_size)\n",
    "    \n",
    "    #pbar.close()\n",
    "\n",
    "    return total_loss / total_examples, total_correct / total_examples\n",
    "\n",
    "@torch.no_grad()\n",
    "def test1():\n",
    "    model.eval()\n",
    "    #pbar = tqdm(total=int(len(train_loader.dataset)+len(val_loader.dataset)+len(test_loader.dataset)))\n",
    "    #pbar.set_description(f'Epoch {epoch:02d} Evaluation: ')\n",
    "    total_correct_train = total_examples_train = 0\n",
    "    total_correct_val = total_examples_val = 0\n",
    "    total_correct_test = total_examples_test = 0\n",
    "    for batch in train_loader:\n",
    "        y = batch.y[:batch.batch_size]\n",
    "        y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
    "        total_correct_train += int((y_hat.argmax(dim=-1) == y).sum())\n",
    "        total_examples_train += batch.batch_size\n",
    "        #pbar.update(batch.batch_size)  \n",
    "    for batch in val_loader:\n",
    "        y = batch.y[:batch.batch_size]\n",
    "        y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
    "        total_correct_val += int((y_hat.argmax(dim=-1) == y).sum())\n",
    "        total_examples_val += batch.batch_size\n",
    "        #pbar.update(batch.batch_size) \n",
    "    for batch in test_loader:\n",
    "        y = batch.y[:batch.batch_size]\n",
    "        y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
    "        total_correct_test += int((y_hat.argmax(dim=-1) == y).sum())\n",
    "        total_examples_test += batch.batch_size\n",
    "        #pbar.update(batch.batch_size)\n",
    "    #pbar.close()\n",
    "    train_acc = total_correct_train / total_examples_train\n",
    "    val_acc =  total_correct_val / total_examples_val\n",
    "    test_acc = total_correct_test / total_examples_test\n",
    "    return  train_acc, val_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3779e82-2fb3-47d0-bf38-f20b995240bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gnn(total_epoch):\n",
    "    loss_epoch= np.zeros(total_epoch)\n",
    "    acc_epoch= np.zeros(total_epoch)\n",
    "    time_epoch = np.zeros(total_epoch)\n",
    "    begin_tt = time()\n",
    "    for epoch in range(1, total_epoch+1):\n",
    "        begin_t = time()\n",
    "        loss_epoch[epoch-1], acc_epoch[epoch-1] = train(epoch)\n",
    "        end_t = time()\n",
    "        time_epoch[epoch-1] = end_t-begin_t\n",
    "    #print(f'Epoch {epoch:02d}, Time {time_epoch[-1]:.4f}, Loss: {loss_epoch[-1]:.4f}, Acc: {acc_epoch[-1]:.4f}')\n",
    "    train_acc, val_acc, test_acc = test1()\n",
    "    end_tt = time()\n",
    "    run_tt = end_tt-begin_tt\n",
    "    print(f'HC: {HC:02d}, NC: {NC:02d},  Time {run_tt:.4f}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
    "      f'Test: {test_acc:.4f}')\n",
    "    return loss_epoch, acc_epoch, time_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c441af-31d8-4b42-86ee-025fd649ffc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC: 16, NC: 04,  Time 129.8561, Train: 0.8933, Val: 0.9012, Test: 0.8998\n",
      "HC: 16, NC: 06,  Time 124.9941, Train: 0.5424, Val: 0.5408, Test: 0.5275\n",
      "HC: 16, NC: 08,  Time 120.4273, Train: 0.0764, Val: 0.1569, Test: 0.1560\n",
      "HC: 32, NC: 04,  Time 120.8244, Train: 0.9180, Val: 0.9242, Test: 0.9241\n",
      "HC: 32, NC: 06,  Time 119.9794, Train: 0.8179, Val: 0.8324, Test: 0.8303\n",
      "HC: 32, NC: 08,  Time 122.1780, Train: 0.0522, Val: 0.0509, Test: 0.0446\n",
      "HC: 128, NC: 04,  Time 124.8450, Train: 0.9600, Val: 0.9545, Test: 0.9555\n",
      "HC: 128, NC: 06,  Time 149.3690, Train: 0.9252, Val: 0.9284, Test: 0.9296\n",
      "HC: 128, NC: 08,  Time 186.5160, Train: 0.3682, Val: 0.3662, Test: 0.3635\n"
     ]
    }
   ],
   "source": [
    "LR=0.003\n",
    "epochs=30\n",
    "rep_time = 1\n",
    "HC=16\n",
    "NC=4\n",
    "HC_list=[16, 32, 128]\n",
    "NC_list=[4, 6, 8]\n",
    "model = pSAGE(dataset.num_features, HC, dataset.num_classes).to(device)\n",
    "loss_train = np.zeros((len(HC_list),len(NC_list),rep_time,epochs))\n",
    "acc_train  = np.zeros((len(HC_list),len(NC_list),rep_time,epochs))\n",
    "time_train  = np.zeros((len(HC_list),len(NC_list),rep_time,epochs))\n",
    "for hhh in range(len(HC_list)):\n",
    "    HC = HC_list[hhh]\n",
    "    for  nnn in range(len(NC_list)):\n",
    "        NC = NC_list[nnn]\n",
    "        model = pSAGE(dataset.num_features, HC, dataset.num_classes).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "        loss_train[hhh,nnn,:], acc_train[hhh,nnn,:],time_train[hhh,nnn,:] =run_gnn(epochs)\n",
    "        path = osp.join(os.path.abspath(''), 'trained_model', 'PSage','PSAGE_HC'+str(HC)+'_NC'+str(NC)+'_EP'+str(epochs)+'_v'+str(rep_time)+'.pt')\n",
    "        torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aac71a2-840a-47a5-8648-2a5bce552d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC: 16, NC: 04,  Time 123.0118, Train: 0.8946, Val: 0.9032, Test: 0.9012\n",
      "HC: 16, NC: 06,  Time 120.8202, Train: 0.6949, Val: 0.7066, Test: 0.7035\n",
      "HC: 16, NC: 08,  Time 119.1872, Train: 0.0802, Val: 0.1966, Test: 0.1984\n",
      "HC: 32, NC: 04,  Time 119.8309, Train: 0.9191, Val: 0.9248, Test: 0.9251\n",
      "HC: 32, NC: 06,  Time 119.8482, Train: 0.7355, Val: 0.7047, Test: 0.7108\n",
      "HC: 32, NC: 08,  Time 114.8595, Train: 0.0549, Val: 0.0527, Test: 0.0513\n",
      "HC: 128, NC: 04,  Time 113.4160, Train: 0.9606, Val: 0.9554, Test: 0.9570\n",
      "HC: 128, NC: 06,  Time 145.7305, Train: 0.9213, Val: 0.9287, Test: 0.9277\n",
      "HC: 128, NC: 08,  Time 185.6597, Train: 0.2295, Val: 0.2190, Test: 0.2152\n"
     ]
    }
   ],
   "source": [
    "rep_time = 2\n",
    "\n",
    "for hhh in range(len(HC_list)):\n",
    "    HC = HC_list[hhh]\n",
    "    for  nnn in range(len(NC_list)):\n",
    "        NC = NC_list[nnn]\n",
    "        model = pSAGE(dataset.num_features, HC, dataset.num_classes).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "        loss_train[hhh,nnn,:], acc_train[hhh,nnn,:],time_train[hhh,nnn,:] =run_gnn(epochs)\n",
    "        path = osp.join(os.path.abspath(''), 'trained_model', 'PSage','PSAGE_HC'+str(HC)+'_NC'+str(NC)+'_EP'+str(epochs)+'_v'+str(rep_time)+'.pt')\n",
    "        torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d0559-5346-4e80-a27f-b94150174b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC: 16, NC: 04,  Time 113.2835, Train: 0.8979, Val: 0.9071, Test: 0.9058\n",
      "HC: 16, NC: 06,  Time 114.1406, Train: 0.7560, Val: 0.7834, Test: 0.7735\n",
      "HC: 16, NC: 08,  Time 113.5848, Train: 0.0497, Val: 0.0399, Test: 0.0445\n",
      "HC: 32, NC: 04,  Time 111.1936, Train: 0.9166, Val: 0.9230, Test: 0.9230\n",
      "HC: 32, NC: 06,  Time 113.4288, Train: 0.7038, Val: 0.7011, Test: 0.7027\n",
      "HC: 32, NC: 08,  Time 113.6899, Train: 0.0671, Val: 0.0566, Test: 0.0528\n",
      "HC: 128, NC: 04,  Time 116.0682, Train: 0.9602, Val: 0.9562, Test: 0.9557\n",
      "HC: 128, NC: 06,  Time 148.3772, Train: 0.9201, Val: 0.9255, Test: 0.9247\n"
     ]
    }
   ],
   "source": [
    "rep_time = 3\n",
    "\n",
    "for hhh in range(len(HC_list)):\n",
    "    HC = HC_list[hhh]\n",
    "    for  nnn in range(len(NC_list)):\n",
    "        NC = NC_list[nnn]\n",
    "        model = pSAGE(dataset.num_features, HC, dataset.num_classes).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "        loss_train[hhh,nnn,:], acc_train[hhh,nnn,:],time_train[hhh,nnn,:] =run_gnn(epochs)\n",
    "        path = osp.join(os.path.abspath(''), 'trained_model', 'PSage','PSAGE_HC'+str(HC)+'_NC'+str(NC)+'_EP'+str(epochs)+'_v'+str(rep_time)+'.pt')\n",
    "        torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ce331f-382b-4c29-80b4-73c64b7af7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = osp.join(os.path.abspath(''), 'trained_model', 'PSage')\n",
    "#np.save(path+'/loss_train.npy',loss_train)\n",
    "#np.save(path+'/acc_train.npy',acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf41a2-7e65-467c-ac1b-8345b80e1dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
