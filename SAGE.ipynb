{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d827a19-c371-4291-a24f-397561683fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path as osp\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from time import *\n",
    "\n",
    "from torch_geometric.datasets import Reddit\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "# download and loading the obg dataset\n",
    "path = osp.join(osp.dirname(osp.realpath('./')), 'data', 'Reddit')\n",
    "dataset = Reddit(path)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device, 'x', 'y')\n",
    "\n",
    "BS=4096\n",
    "kwargs = {'batch_size': BS, 'num_workers': 6, 'persistent_workers': True}\n",
    "train_loader = NeighborLoader(data, input_nodes=data.train_mask,\n",
    "                              num_neighbors=[25, 10], shuffle=True, **kwargs)\n",
    "test_loader = NeighborLoader(data, input_nodes=data.test_mask,\n",
    "                              num_neighbors=[25, 10], shuffle=True, **kwargs)\n",
    "val_loader = NeighborLoader(data, input_nodes=data.val_mask,\n",
    "                              num_neighbors=[25, 10], shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d07c6b-4b4c-4a36-b145-c4caa44af577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for i in range(NC-2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i < len(self.convs) - 1:\n",
    "                x = x.relu_()\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x\n",
    "    \n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    #pbar = tqdm(total=int(len(train_loader.dataset)))\n",
    "    #pbar.set_description(f'Epoch {epoch:02d}')\n",
    "\n",
    "    total_loss = total_correct = total_examples = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y = batch.y[:batch.batch_size]\n",
    "        y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * batch.batch_size\n",
    "        total_correct += int((y_hat.argmax(dim=-1) == y).sum())\n",
    "        total_examples += batch.batch_size\n",
    "        #pbar.update(batch.batch_size)\n",
    "    \n",
    "    #pbar.close()\n",
    "\n",
    "    return total_loss / total_examples, total_correct / total_examples\n",
    "\n",
    "@torch.no_grad()\n",
    "def test1():\n",
    "    model.eval()\n",
    "    #pbar = tqdm(total=int(len(train_loader.dataset)+len(val_loader.dataset)+len(test_loader.dataset)))\n",
    "    #pbar.set_description(f'Epoch {epoch:02d} Evaluation: ')\n",
    "    total_correct_train = total_examples_train = 0\n",
    "    total_correct_val = total_examples_val = 0\n",
    "    total_correct_test = total_examples_test = 0\n",
    "    for batch in train_loader:\n",
    "        y = batch.y[:batch.batch_size]\n",
    "        y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
    "        total_correct_train += int((y_hat.argmax(dim=-1) == y).sum())\n",
    "        total_examples_train += batch.batch_size\n",
    "        #pbar.update(batch.batch_size)  \n",
    "    for batch in val_loader:\n",
    "        y = batch.y[:batch.batch_size]\n",
    "        y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
    "        total_correct_val += int((y_hat.argmax(dim=-1) == y).sum())\n",
    "        total_examples_val += batch.batch_size\n",
    "        #pbar.update(batch.batch_size) \n",
    "    for batch in test_loader:\n",
    "        y = batch.y[:batch.batch_size]\n",
    "        y_hat = model(batch.x, batch.edge_index.to(device))[:batch.batch_size]\n",
    "        total_correct_test += int((y_hat.argmax(dim=-1) == y).sum())\n",
    "        total_examples_test += batch.batch_size\n",
    "        #pbar.update(batch.batch_size)\n",
    "    #pbar.close()\n",
    "    train_acc = total_correct_train / total_examples_train\n",
    "    val_acc =  total_correct_val / total_examples_val\n",
    "    test_acc = total_correct_test / total_examples_test\n",
    "    return  train_acc, val_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2049dfaf-23e5-4719-b2a6-4dd96b358514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gnn(total_epoch):\n",
    "    loss_epoch= np.zeros(total_epoch)\n",
    "    acc_epoch= np.zeros(total_epoch)\n",
    "    time_epoch = np.zeros(total_epoch)\n",
    "    begin_tt = time()\n",
    "    for epoch in range(1, total_epoch+1):\n",
    "        begin_t = time()\n",
    "        loss_epoch[epoch-1], acc_epoch[epoch-1] = train(epoch)\n",
    "        end_t = time()\n",
    "        time_epoch[epoch-1] = end_t-begin_t\n",
    "    #print(f'Epoch {epoch:02d}, Time {time_epoch[-1]:.4f}, Loss: {loss_epoch[-1]:.4f}, Acc: {acc_epoch[-1]:.4f}')\n",
    "    train_acc, val_acc, test_acc = test1()\n",
    "    end_tt = time()\n",
    "    run_tt = end_tt-begin_tt\n",
    "    print(f'HC: {HC:02d}, NC: {NC:02d},  Time {run_tt:.4f}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
    "      f'Test: {test_acc:.4f}')\n",
    "    return loss_epoch, acc_epoch, time_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d4ccf6-75fc-4ee4-8420-c920aedce6f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC: 16, NC: 06,  Time 120.7811, Train: 0.8863, Val: 0.8952, Test: 0.8946\n",
      "HC: 16, NC: 10,  Time 112.0392, Train: 0.6103, Val: 0.6507, Test: 0.6345\n",
      "HC: 16, NC: 14,  Time 112.8161, Train: 0.0260, Val: 0.0271, Test: 0.0248\n",
      "HC: 32, NC: 06,  Time 112.6944, Train: 0.9196, Val: 0.9264, Test: 0.9257\n",
      "HC: 32, NC: 10,  Time 112.3423, Train: 0.8527, Val: 0.8549, Test: 0.8581\n",
      "HC: 32, NC: 14,  Time 110.6557, Train: 0.0606, Val: 0.0537, Test: 0.0538\n",
      "HC: 128, NC: 06,  Time 111.9009, Train: 0.9632, Val: 0.9580, Test: 0.9576\n",
      "HC: 128, NC: 10,  Time 132.7848, Train: 0.9193, Val: 0.9232, Test: 0.9238\n",
      "HC: 128, NC: 14,  Time 168.1328, Train: 0.2191, Val: 0.2856, Test: 0.2816\n"
     ]
    }
   ],
   "source": [
    "rep_time = 1\n",
    "LR=0.003\n",
    "epochs=30\n",
    "HC=16\n",
    "NC=6\n",
    "HC_list=[16, 32, 128]\n",
    "NC_list=[6, 10, 14]\n",
    "model = SAGE(dataset.num_features, HC, dataset.num_classes).to(device)\n",
    "loss_train = np.zeros((len(HC_list),len(NC_list),epochs))\n",
    "acc_train  = np.zeros((len(HC_list),len(NC_list),epochs))\n",
    "time_train  = np.zeros((len(HC_list),len(NC_list),epochs))\n",
    "for hhh in range(len(HC_list)):\n",
    "    HC = HC_list[hhh]\n",
    "    for  nnn in range(len(NC_list)):\n",
    "        NC = NC_list[nnn]\n",
    "        model = SAGE(dataset.num_features, HC, dataset.num_classes).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "        loss_train[hhh,nnn,:], acc_train[hhh,nnn,:],time_train[hhh,nnn,:] =run_gnn(epochs)\n",
    "        path = osp.join(os.path.abspath(''), 'trained_model', 'Sage1','SAGE_HC'+str(HC)+'_NC'+str(NC)+'_EP'+str(epochs)+'_v'+str(rep_time)+'.pt')\n",
    "        torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ea98dd7-a425-40f2-94dc-5efcff3ddccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC: 16, NC: 06,  Time 113.0997, Train: 0.8898, Val: 0.9006, Test: 0.8981\n",
      "HC: 16, NC: 10,  Time 112.1445, Train: 0.5806, Val: 0.6144, Test: 0.6082\n",
      "HC: 16, NC: 14,  Time 111.4994, Train: 0.0785, Val: 0.0778, Test: 0.0720\n",
      "HC: 32, NC: 06,  Time 112.5869, Train: 0.9206, Val: 0.9267, Test: 0.9259\n",
      "HC: 32, NC: 10,  Time 113.2091, Train: 0.7894, Val: 0.8113, Test: 0.8105\n",
      "HC: 32, NC: 14,  Time 112.7193, Train: 0.1325, Val: 0.1122, Test: 0.1051\n",
      "HC: 128, NC: 06,  Time 110.4762, Train: 0.9634, Val: 0.9581, Test: 0.9573\n",
      "HC: 128, NC: 10,  Time 133.5865, Train: 0.9290, Val: 0.9325, Test: 0.9322\n",
      "HC: 128, NC: 14,  Time 168.2834, Train: 0.1347, Val: 0.1239, Test: 0.1219\n"
     ]
    }
   ],
   "source": [
    "rep_time = 2\n",
    "LR=0.003\n",
    "epochs=30\n",
    "HC=16\n",
    "NC=6\n",
    "HC_list=[16, 32, 128]\n",
    "NC_list=[6, 10, 14]\n",
    "model = SAGE(dataset.num_features, HC, dataset.num_classes).to(device)\n",
    "loss_train = np.zeros((len(HC_list),len(NC_list),epochs))\n",
    "acc_train  = np.zeros((len(HC_list),len(NC_list),epochs))\n",
    "time_train  = np.zeros((len(HC_list),len(NC_list),epochs))\n",
    "for hhh in range(len(HC_list)):\n",
    "    HC = HC_list[hhh]\n",
    "    for  nnn in range(len(NC_list)):\n",
    "        NC = NC_list[nnn]\n",
    "        model = SAGE(dataset.num_features, HC, dataset.num_classes).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "        loss_train[hhh,nnn,:], acc_train[hhh,nnn,:],time_train[hhh,nnn,:] =run_gnn(epochs)\n",
    "        path = osp.join(os.path.abspath(''), 'trained_model', 'Sage1','SAGE_HC'+str(HC)+'_NC'+str(NC)+'_EP'+str(epochs)+'_v'+str(rep_time)+'.pt')\n",
    "        torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d61580e3-5f2f-44ba-9d32-50208e76233d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC: 16, NC: 06,  Time 111.9119, Train: 0.8953, Val: 0.9036, Test: 0.9032\n",
      "HC: 16, NC: 10,  Time 112.9148, Train: 0.7142, Val: 0.6817, Test: 0.6751\n",
      "HC: 16, NC: 14,  Time 112.7656, Train: 0.0218, Val: 0.0212, Test: 0.0208\n",
      "HC: 32, NC: 06,  Time 112.6068, Train: 0.9221, Val: 0.9269, Test: 0.9272\n",
      "HC: 32, NC: 10,  Time 111.8981, Train: 0.8164, Val: 0.8191, Test: 0.8195\n",
      "HC: 32, NC: 14,  Time 111.8104, Train: 0.0930, Val: 0.0917, Test: 0.0856\n",
      "HC: 128, NC: 06,  Time 110.0512, Train: 0.9642, Val: 0.9590, Test: 0.9582\n",
      "HC: 128, NC: 10,  Time 132.0968, Train: 0.9202, Val: 0.9249, Test: 0.9239\n",
      "HC: 128, NC: 14,  Time 167.7234, Train: 0.1546, Val: 0.1339, Test: 0.1310\n"
     ]
    }
   ],
   "source": [
    "rep_time = 3\n",
    "LR=0.003\n",
    "epochs=30\n",
    "HC=16\n",
    "NC=6\n",
    "HC_list=[16, 32, 128]\n",
    "NC_list=[6, 10, 14]\n",
    "model = SAGE(dataset.num_features, HC, dataset.num_classes).to(device)\n",
    "loss_train = np.zeros((len(HC_list),len(NC_list),epochs))\n",
    "acc_train  = np.zeros((len(HC_list),len(NC_list),epochs))\n",
    "time_train  = np.zeros((len(HC_list),len(NC_list),epochs))\n",
    "for hhh in range(len(HC_list)):\n",
    "    HC = HC_list[hhh]\n",
    "    for  nnn in range(len(NC_list)):\n",
    "        NC = NC_list[nnn]\n",
    "        model = SAGE(dataset.num_features, HC, dataset.num_classes).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "        loss_train[hhh,nnn,:], acc_train[hhh,nnn,:],time_train[hhh,nnn,:] =run_gnn(epochs)\n",
    "        path = osp.join(os.path.abspath(''), 'trained_model', 'Sage1','SAGE_HC'+str(HC)+'_NC'+str(NC)+'_EP'+str(epochs)+'_v'+str(rep_time)+'.pt')\n",
    "        torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459fad65-b899-496b-9e53-03819034bdd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
